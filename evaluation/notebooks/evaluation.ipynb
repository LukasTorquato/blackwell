{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cdedb3",
   "metadata": {},
   "source": [
    "**Warning:**\n",
    "\n",
    "To run this notebook, the .ipynb file must be in the  project root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b27c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from blackwell.prompts import final_report_prompt\n",
    "from blackwell.anamnesis import AnamnesisAgent\n",
    "from blackwell.evaluator import EvaluatorAgent\n",
    "from blackwell.prompts import ai_patient_prompt\n",
    "from blackwell.config import fast_model, pro_model, logger\n",
    "from evaluation.aip import AiPatient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23338789",
   "metadata": {},
   "source": [
    "## Anamnesis Reports Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d77f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, shuffle, and split into X and y\n",
    "dataset = pd.read_csv(\"evaluation/dataset/Training.csv\")\n",
    "dataset = dataset.sample(frac=1, random_state=44).reset_index(drop=True)\n",
    "X = dataset.iloc[0:, :-1].reset_index(drop=True) #Symptoms\n",
    "y = dataset.iloc[0:, -1].reset_index(drop=True) #Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"evaluation/anamnesis_output.csv\")\n",
    "except FileNotFoundError:\n",
    "    sample_size = 250\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(sample_size):\n",
    "        if X.iloc[i]['coma'] == 1:\n",
    "            print(\"Skipping coma case for safety.\")\n",
    "            continue\n",
    "        symptoms = X.iloc[i].to_json()\n",
    "        condition = y.iloc[i]\n",
    "        case_study = {\"true_condition\": condition, \"patient_profile\": symptoms, \"exchanges\": 0, \"anamnesis_report\": \"none\"}\n",
    "        df = pd.concat([df, pd.DataFrame([case_study])], ignore_index=True)\n",
    "    df = pd.DataFrame(columns=[\"patient_profile\",\"true_condition\", \"aip_query\", \"final_report\"])\n",
    "    df.to_csv(\"evaluation/anamnesis_output.csv\", index=False)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency words to halt the anamnesis if detected\n",
    "emergency_words = [\"emergency\", \"immediately\", \"urgent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0eb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the anamnesis simulation for each patient case\n",
    "number_of_cases = 250\n",
    "for i in tqdm(range(number_of_cases)):\n",
    "    verbose = False\n",
    "    symptoms = df[\"patient_profile\"].iloc[i]\n",
    "    condition = df[\"true_condition\"].iloc[i]\n",
    "    # Generate patient profile\n",
    "    patient_profile = ai_patient_prompt.content.format(PATIENT_PROFILE=symptoms, PATIENT_CONDITION=condition)\n",
    "    config = {\"configurable\": {\"thread_id\": np.random.randint(10, 100000)}}\n",
    "\n",
    "    # Start the anamnesis interaction loop between AiPatient and AnamnesisAgent\n",
    "    p_result = AiPatient.invoke({\"messages\": \"Initiate your introduction.\" , \"profile\": patient_profile}, config)\n",
    "    result = AnamnesisAgent.invoke({\"messages\": [HumanMessage(content=p_result['messages'][-1].content)], \"function\": \"chat\", \"final_report\": None, \"documents_report\": None}, config)\n",
    "\n",
    "    # Continue the interaction until a final report is generated or max exchanges reached\n",
    "    while (result[\"final_report\"] is None) and (len(result[\"messages\"]) < 35):\n",
    "        p_result = AiPatient.invoke({\"messages\": [HumanMessage(content=result['messages'][-1].content)], \"profile\": patient_profile}, config)\n",
    "        print(\"Patient Response:\") if verbose else None\n",
    "        print(p_result['messages'][-1].content) if verbose else None\n",
    "        result = AnamnesisAgent.invoke({\"messages\": [HumanMessage(content=p_result['messages'][-1].content)]}, config)\n",
    "        print(\"Agent Response:\") if verbose else None\n",
    "        print(result['messages'][-1].content) if verbose else None\n",
    "        report = result[\"final_report\"]\n",
    "        if any(word in result['messages'][-1].content.lower() for word in emergency_words):\n",
    "            print(\"Emergency detected, going to next case.\")\n",
    "            report = \"EMERGENCY DETECTED. Anamnesis aborted.\"\n",
    "            break\n",
    "        # Time delay to avoid rate limiting\n",
    "        #time.sleep(10)\n",
    "    if len(result[\"messages\"]) >= 35:\n",
    "        print(\"Max exchanges reached, moving to next case.\")\n",
    "        continue\n",
    "\n",
    "    print(\"True Condition:\", condition)\n",
    "    print(\"Anamnesis Completed with: \", len(result[\"messages\"]), \" exchanges.\")\n",
    "    df.loc[i, 'exchanges'] = len(result[\"messages\"])\n",
    "    df.loc[i, 'anamnesis_report'] = json.dumps(report)\n",
    "    p_result = None\n",
    "    result = None\n",
    "    # Save the results to CSV\n",
    "    df.to_csv(\"evaluation/anamnesis_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1afac",
   "metadata": {},
   "source": [
    "## Evaluator Reports Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bf930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    reports = pd.read_csv(\"evaluation/evaluator_output.csv\")\n",
    "except FileNotFoundError:\n",
    "    reports = pd.read_csv(\"evaluation/anamnesis_output.csv\")\n",
    "    reports.loc[:, 'final_report'] = 'none'\n",
    "    reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)\n",
    "len(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce446d4e",
   "metadata": {},
   "source": [
    "#### Procedural Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf306c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index  249\n",
      "Proposing Hypothesis query...\n",
      "RAG Agent researching...\n",
      "RAG Agent completed research with 6 messages\n",
      "Assessing clinical certainty expert...\n",
      "Running investigator expert...\n",
      "Generating hypothesis report...\n",
      "Proposing Treatment query...\n",
      "RAG Agent researching...\n",
      "RAG Agent completed research with 14 messages\n",
      "Performing PubMed search for additional context...\n",
      "PubMed Agent completed research with 14 messages\n",
      "Generating treatment plan...\n",
      "Generating final report...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reports)):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Processing index \", i)\n",
    "    logger.info(f\"Processing index {i}\")\n",
    "    \n",
    "    if reports.loc[i, \"final_report\"] not in [\"none\", \"rerun\"]:\n",
    "        continue\n",
    "    ar = json.loads(reports[\"anamnesis_report\"][i])\n",
    "\n",
    "    if \"EMERGENCY DETECTED\" in ar:\n",
    "        logger.info(f\"Emergency detected in index {i}, skipping evaluation.\")\n",
    "        reports.loc[i, \"final_report\"] = json.dumps(ar)\n",
    "        reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)\n",
    "        continue\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": np.random.rand()}, \"recursion_limit\": 50}\n",
    "    initial_state = {\"references\": [], \"t_run\": 0, \"anamnesis_report\": HumanMessage(content=ar), \"query\": None, \"reports\": {}, \"final_report\": None}\n",
    "    result = EvaluatorAgent.invoke(initial_state, config)\n",
    "    final_report = result[\"final_report\"]\n",
    "    reports.loc[i, \"final_report\"] = json.dumps(final_report)\n",
    "    reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)\n",
    "    logger.info(f\"Final report for index {i} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede6135",
   "metadata": {},
   "source": [
    "## Stock Model Evaluator Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2546b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    reports = pd.read_csv(\"evaluation/evaluator_stock.csv\")\n",
    "except FileNotFoundError:\n",
    "    reports = pd.read_csv(\"evaluation/anamnesis_output.csv\")\n",
    "    reports.loc[:, 'final_report'] = 'none'\n",
    "    reports.to_csv(\"evaluation/evaluator_stock.csv\", index=False)\n",
    "len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2212e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reports)):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Processing index \", i)\n",
    "    logger.info(f\"Processing index {i}\")\n",
    "    \n",
    "    if reports.loc[i, \"final_report\"] not in [\"none\", \"rerun\"]:\n",
    "        continue\n",
    "    ar = json.loads(reports[\"anamnesis_report\"][i])\n",
    "\n",
    "    if \"EMERGENCY DETECTED\" in ar:\n",
    "        logger.info(f\"Emergency detected in index {i}, skipping evaluation.\")\n",
    "        reports.loc[i, \"final_report\"] = json.dumps(ar)\n",
    "        reports.to_csv(\"evaluation/evaluator_stock.csv\", index=False)\n",
    "        continue\n",
    "\n",
    "    an = HumanMessage(content=ar)\n",
    "    result = pro_model.invoke([final_report_prompt] + [an])\n",
    "        \n",
    "    final_report = result.content\n",
    "    reports.loc[i, \"final_report\"] = json.dumps(final_report)\n",
    "    reports.to_csv(\"evaluation/evaluator_stock.csv\", index=False)\n",
    "    logger.info(f\"Final report for index {i} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb3e98",
   "metadata": {},
   "source": [
    "## Raw Model Evaluator Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfb0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, shuffle, and split into X and y\n",
    "dataset = pd.read_csv(\"evaluation/dataset/Training.csv\")\n",
    "dataset = dataset.sample(frac=1, random_state=44).reset_index(drop=True)\n",
    "X = dataset.iloc[0:, :-1].reset_index(drop=True) #Symptoms\n",
    "y = dataset.iloc[0:, -1].reset_index(drop=True) #Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create or load the raw evaluation dataset\n",
    "try:\n",
    "    sample_size = 250\n",
    "    raw_eval = pd.read_csv(\"evaluation/evaluator_raw.csv\")\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame()\n",
    "    i = -1\n",
    "    while len(df) < sample_size:\n",
    "        i += 1\n",
    "        if X.iloc[i]['coma'] == 1:\n",
    "            print(\"Skipping coma case for safety.\")\n",
    "            continue\n",
    "        symptoms = X.iloc[i].to_json()\n",
    "        condition = y.iloc[i]\n",
    "        case_study = {\"true_condition\": condition, \"patient_profile\": symptoms, \"aip_query\": \"none\", \"final_report\": \"none\"}\n",
    "        df = pd.concat([df, pd.DataFrame([case_study])], ignore_index=True)\n",
    "    df.to_csv(\"evaluation/evaluator_raw.csv\", index=False)\n",
    "    raw_eval = df\n",
    "len(raw_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b8c0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prompt = SystemMessage(content=\"\"\"You are a highly intelligent medical evaluator AI.\n",
    "                            Your task is to provide a Probable Diagnosis based on the complaint of the patient.content_blocks=\n",
    "                            Provide the main probable diagnosis like \"Probable Diagnosis: <diagnosis>\"\n",
    "                            Provide differential diagnoses as \"Differential Diagnoses: <diagnosis1>, <diagnosis2>, ...\"\n",
    "                            If necessary provide Exams to confirm the diagnosis.\n",
    "                            Provide a thorough treatment plan as \"Treatment Plan: <plan>\"\n",
    "                            Here is the patient's complaint:\n",
    "                           \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e41cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb1b9d2606c4edcbdf50a5269ead15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Condition: Urinary tract infection\n",
      "True Condition: Allergy\n",
      "True Condition: Diabetes \n",
      "True Condition: Urinary tract infection\n",
      "True Condition: (vertigo) Paroymsal  Positional Vertigo\n",
      "True Condition: Tuberculosis\n",
      "True Condition: Osteoarthristis\n",
      "True Condition: Hypoglycemia\n",
      "True Condition: Typhoid\n",
      "True Condition: Arthritis\n",
      "True Condition: Psoriasis\n",
      "True Condition: Dimorphic hemmorhoids(piles)\n",
      "True Condition: Hypothyroidism\n",
      "True Condition: Alcoholic hepatitis\n",
      "True Condition: Gastroenteritis\n",
      "True Condition: Heart attack\n",
      "True Condition: Malaria\n",
      "True Condition: Impetigo\n",
      "True Condition: Hypoglycemia\n",
      "True Condition: AIDS\n",
      "True Condition: Bronchial Asthma\n",
      "True Condition: AIDS\n",
      "True Condition: Urinary tract infection\n",
      "True Condition: Gastroenteritis\n",
      "True Condition: Gastroenteritis\n",
      "True Condition: Dengue\n",
      "True Condition: Migraine\n",
      "True Condition: GERD\n",
      "True Condition: Allergy\n",
      "True Condition: Osteoarthristis\n",
      "True Condition: (vertigo) Paroymsal  Positional Vertigo\n",
      "True Condition: Paralysis (brain hemorrhage)\n",
      "True Condition: Varicose veins\n",
      "True Condition: Diabetes \n",
      "True Condition: Varicose veins\n",
      "True Condition: Fungal infection\n",
      "True Condition: Hepatitis D\n",
      "True Condition: Diabetes \n",
      "True Condition: Chronic cholestasis\n",
      "True Condition: Dengue\n",
      "True Condition: Hypothyroidism\n",
      "True Condition: Hepatitis D\n",
      "True Condition: Hypothyroidism\n",
      "True Condition: Hepatitis C\n",
      "True Condition: Malaria\n",
      "True Condition: Jaundice\n",
      "True Condition: Hypertension \n",
      "True Condition: Dimorphic hemmorhoids(piles)\n"
     ]
    }
   ],
   "source": [
    "# Run the anamnesis simulation for each patient case\n",
    "sample_size = 100\n",
    "for i in tqdm(range(sample_size)):\n",
    "    verbose = False\n",
    "    symptoms = raw_eval[\"patient_profile\"].iloc[i]\n",
    "    condition = raw_eval[\"true_condition\"].iloc[i]\n",
    "    if raw_eval.loc[i, 'final_report'] not in [\"none\", \"rerun\"]:\n",
    "        continue\n",
    "    # Generate patient profile\n",
    "    patient_profile = ai_patient_prompt.content.format(PATIENT_PROFILE=symptoms, PATIENT_CONDITION=condition)\n",
    "    config = {\"configurable\": {\"thread_id\": np.random.randint(10, 100000)}}\n",
    "\n",
    "    # Start the anamnesis interaction loop between AiPatient and AnamnesisAgent\n",
    "    p_result = AiPatient.invoke({\"messages\": \"Initiate your introduction with you chief complaint and how you are feeling\" , \"profile\": patient_profile}, config)\n",
    "    aip_query = HumanMessage(content=p_result['messages'][-1].content)\n",
    "    \n",
    "    result = pro_model.invoke([raw_prompt] + [aip_query])\n",
    "    report = result.content\n",
    "\n",
    "    print(\"True Condition:\", condition)\n",
    "    raw_eval.loc[i, 'aip_query'] = json.dumps(aip_query.content)\n",
    "    raw_eval.loc[i, 'final_report'] = json.dumps(report)\n",
    "    p_result = None\n",
    "    result = None\n",
    "    # Save the results to CSV\n",
    "    raw_eval.to_csv(\"evaluation/evaluator_raw.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
