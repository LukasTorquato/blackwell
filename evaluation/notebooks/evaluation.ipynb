{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cdedb3",
   "metadata": {},
   "source": [
    "#### Warning:\n",
    "To run this must be in the \"blackwell\" package root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b27c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from langchain_core.messages import HumanMessage\n",
    "from blackwell.anamnesis import AnamnesisAgent\n",
    "from blackwell.evaluator import EvaluatorAgent\n",
    "from blackwell.prompts import ai_patient_prompt\n",
    "from blackwell.config import fast_model, agent_model, pro_model, logger\n",
    "from evaluation.aip import AiPatient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23338789",
   "metadata": {},
   "source": [
    "## Anamnesis Procedure Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d77f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, shuffle, and split into X and y\n",
    "dataset = pd.read_csv(\"evaluation/dataset/Training.csv\")\n",
    "dataset = dataset.sample(frac=1, random_state=44).reset_index(drop=True)\n",
    "X = dataset.iloc[0:, :-1].reset_index(drop=True) #Symptoms\n",
    "y = dataset.iloc[0:, -1].reset_index(drop=True) #Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d17abae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"evaluation/anamnesis_output.csv\")\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency words to halt the anamnesis if detected\n",
    "emergency_words = [\"emergency\", \"immediately\", \"urgent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0eb325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757379fc13d44e1fbed6defa99278f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emergency detected, going to next case.\n",
      "True Condition: GERD\n",
      "Anamnesis Completed with:  4  exchanges.\n",
      "True Condition: Peptic ulcer diseae\n",
      "Anamnesis Completed with:  18  exchanges.\n"
     ]
    }
   ],
   "source": [
    "# Run the anamnesis simulation for each patient case\n",
    "number_of_cases = 250\n",
    "for i in tqdm(range(number_of_cases)):\n",
    "    verbose = False\n",
    "    if X.iloc[i]['coma'] == 1:\n",
    "        print(\"Skipping coma case for safety.\")\n",
    "        continue\n",
    "    symptoms = X.iloc[i].to_json()\n",
    "    condition = y.iloc[i]\n",
    "    # Generate patient profile\n",
    "    patient_profile = ai_patient_prompt.content.format(PATIENT_PROFILE=symptoms, PATIENT_CONDITION=condition)\n",
    "    config = {\"configurable\": {\"thread_id\": np.random.randint(10, 100000)}}\n",
    "\n",
    "    # Start the anamnesis interaction loop between AiPatient and AnamnesisAgent\n",
    "    p_result = AiPatient.invoke({\"messages\": \"Initiate your introduction.\" , \"profile\": patient_profile}, config)\n",
    "    result = AnamnesisAgent.invoke({\"messages\": [HumanMessage(content=p_result['messages'][-1].content)], \"function\": \"chat\", \"final_report\": None, \"documents_report\": None}, config)\n",
    "\n",
    "    # Continue the interaction until a final report is generated or max exchanges reached\n",
    "    while (result[\"final_report\"] is None) and (len(result[\"messages\"]) < 35):\n",
    "        p_result = AiPatient.invoke({\"messages\": [HumanMessage(content=result['messages'][-1].content)], \"profile\": patient_profile}, config)\n",
    "        print(\"Patient Response:\") if verbose else None\n",
    "        print(p_result['messages'][-1].content) if verbose else None\n",
    "        result = AnamnesisAgent.invoke({\"messages\": [HumanMessage(content=p_result['messages'][-1].content)]}, config)\n",
    "        print(\"Agent Response:\") if verbose else None\n",
    "        print(result['messages'][-1].content) if verbose else None\n",
    "        report = result[\"final_report\"]\n",
    "        if any(word in result['messages'][-1].content.lower() for word in emergency_words):\n",
    "            print(\"Emergency detected, going to next case.\")\n",
    "            report = \"EMERGENCY DETECTED. Anamnesis aborted.\"\n",
    "            break\n",
    "        # Time delay to avoid rate limiting\n",
    "        #time.sleep(10)\n",
    "    if len(result[\"messages\"]) >= 35:\n",
    "        print(\"Max exchanges reached, moving to next case.\")\n",
    "        continue\n",
    "\n",
    "    print(\"True Condition:\", condition)\n",
    "    print(\"Anamnesis Completed with: \", len(result[\"messages\"]), \" exchanges.\")\n",
    "    case_study = {\"patient_profile\": symptoms, \"anamnesis_report\": json.dumps(report), \"true_condition\": condition, \"exchanges\": len(result[\"messages\"])}\n",
    "    p_result = None\n",
    "    result = None\n",
    "    # Save the results to CSV\n",
    "    df = pd.concat([df, pd.DataFrame([case_study])], ignore_index=True)\n",
    "    df.to_csv(\"evaluation/anamnesis_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1afac",
   "metadata": {},
   "source": [
    "## Evaluator Procedure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bf930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    reports = pd.read_csv(\"evaluation/evaluator_output.csv\")\n",
    "except FileNotFoundError:\n",
    "    reports = pd.read_csv(\"evaluation/anamnesis_output.csv\")\n",
    "    reports.loc[:, 'final_report'] = 'none'\n",
    "    reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)\n",
    "len(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa351850",
   "metadata": {},
   "source": [
    "#### Single Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283eba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(reports.loc[102, \"anamnesis_report\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8096d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.loc[216, \"final_report\"] = \"rerun\"\n",
    "reports.loc[245, \"final_report\"] = \"rerun\"\n",
    "reports.loc[249, \"final_report\"] = \"rerun\"\n",
    "reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe3a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = \"[ANAMNESIS REPORT]:\"+json.loads(reports[\"anamnesis_report\"][0]).split(\"[ANAMNESIS REPORT]:\" )[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": np.random.rand()}, \"recursion_limit\": 100}\n",
    "initial_state = {\"references\": [], \"t_run\": 0, \"anamnesis_report\": HumanMessage(content=an), \"query\": None, \"reports\": {}, \"final_report\": None}\n",
    "result = EvaluatorAgent.invoke(initial_state, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce446d4e",
   "metadata": {},
   "source": [
    "#### Procedural Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf306c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index  249\n",
      "Proposing Hypothesis query...\n",
      "RAG Agent researching...\n",
      "RAG Agent completed research with 6 messages\n",
      "Assessing clinical certainty expert...\n",
      "Running investigator expert...\n",
      "Generating hypothesis report...\n",
      "Proposing Treatment query...\n",
      "RAG Agent researching...\n",
      "RAG Agent completed research with 14 messages\n",
      "Performing PubMed search for additional context...\n",
      "PubMed Agent completed research with 14 messages\n",
      "Generating treatment plan...\n",
      "Generating final report...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reports)):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Processing index \", i)\n",
    "    logger.info(f\"Processing index {i}\")\n",
    "    \n",
    "    if reports.loc[i, \"final_report\"] not in [\"none\", \"rerun\"]:\n",
    "        continue\n",
    "    ar = json.loads(reports[\"anamnesis_report\"][i])\n",
    "\n",
    "    if \"EMERGENCY DETECTED\" in ar:\n",
    "        logger.info(f\"Emergency detected in index {i}, skipping evaluation.\")\n",
    "        reports.loc[i, \"final_report\"] = json.dumps(ar)\n",
    "        reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)\n",
    "        continue\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": np.random.rand()}, \"recursion_limit\": 50}\n",
    "    initial_state = {\"references\": [], \"t_run\": 0, \"anamnesis_report\": HumanMessage(content=ar), \"query\": None, \"reports\": {}, \"final_report\": None}\n",
    "    result = EvaluatorAgent.invoke(initial_state, config)\n",
    "    final_report = result[\"final_report\"]\n",
    "    reports.loc[i, \"final_report\"] = json.dumps(final_report)\n",
    "    reports.to_csv(\"evaluation/evaluator_output.csv\", index=False)\n",
    "    logger.info(f\"Final report for index {i} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342e0bb",
   "metadata": {},
   "source": [
    "### Expected Evaluation Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090ea80",
   "metadata": {},
   "source": [
    "* Processing index  191\n",
    "* Proposing Hypothesis query...\n",
    "* RAG Agent researching...\n",
    "* RAG Agent completed research with 12 messages\n",
    "* Assessing clinical certainty expert...\n",
    "* Running investigator expert...\n",
    "* Generating hypothesis report...\n",
    "* Proposing Treatment query...\n",
    "* RAG Agent researching...\n",
    "* RAG Agent completed research with 14 messages\n",
    "* Performing PubMed search for additional context...\n",
    "* PubMed Agent completed research with 124 messages\n",
    "* Generating treatment plan...\n",
    "* Generating final report..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
